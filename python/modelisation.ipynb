{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class motion_detection:\n",
    "    \n",
    "    # to-do : un load model\n",
    "    \n",
    "    # voir pour mettre les parametre variate dans la fonction start plutot que dans l'init\n",
    "\n",
    "    def _create_model(self):\n",
    "        # creation of a sequential model\n",
    "        # 3 layers : 2 LSTM and 1 Dense\n",
    "        # LSTM = Long Short Memory layer\n",
    "        # Dense = a regular densely-connected NN layer\n",
    "    \n",
    "        model = Sequential()\n",
    "        # no parameter of Sequential function\n",
    "        model.add(LSTM( self.nb_neurons[0], activation = self.activation, \n",
    "                       return_sequences = True,\n",
    "                       input_shape = self.input_shape,\n",
    "                       recurrent_dropout = self.recu_dropout))\n",
    "        model.add(LSTM(self.nb_neurons[1],\n",
    "                       recurrent_dropout = self.recu_dropout))\n",
    "        #model.add(BatchNormalization())\n",
    "        #model.add(Dropout(self.recu_dropout))\n",
    "        #model.add(BatchNormalization())\n",
    "        model.add(Dense( self.nb_labels, activation = 'softmax' ))\n",
    "        \n",
    "        model.compile( loss = \"mse\", \n",
    "                      optimizer = optimizers.Adam(lr = self.learning_rate),\n",
    "                     metrics = ['accuracy'])\n",
    "        \n",
    "#         log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#         tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        \n",
    "        print(model.summary())\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def _create_model_hirerachique(self):\n",
    "        # fonctionne uniquement sur les donn√©es de la neuron pro\n",
    "        \n",
    "        model = Sequentiel()\n",
    "        \n",
    "        tronc = Sequentiel()\n",
    "        # vertebre : 43 - 48\n",
    "        # vertebre 1 : 49 - 54\n",
    "        # vertebre 2 : 55 - 60\n",
    "        # vertebre 3 : 61 - 66\n",
    "        # nuque : 67 - 72\n",
    "        # tete : 73 - 78\n",
    "        \n",
    "        \n",
    "        bras_g = Sequentiel()\n",
    "        # epaule gauche : 217 - 222\n",
    "        # biceps gauche : 223 - 228\n",
    "        # avant-bras gauche : 229 - 234\n",
    "        # main gauche : 235 - 240\n",
    "        \n",
    "        bras_d = Sequentiel()\n",
    "        # epaule droite : 79 - 84\n",
    "        # biceps droit : 85 - 90\n",
    "        # avant-bras droit : 91 - 96\n",
    "        # main droite : 97 - 102\n",
    "        \n",
    "        jambe_g = Sequentiel()\n",
    "        # cuisse gauche : 25 - 30\n",
    "        # mollet gauche : 31 - 36\n",
    "        # pied gauche : 37 - 42\n",
    "        \n",
    "        jambe_d = Sequentiel()\n",
    "        # cuisse droite : 7 - 12\n",
    "        # mollet droit : 13 - 18\n",
    "        # pied droit : 19 - 24\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def _model_fit(self):\n",
    "        # training time\n",
    "        start_time = time.time()\n",
    "        self.algo_start_time = start_time\n",
    "        self.history = self.model.fit(self.x_train, self.y_train , \n",
    "                       epochs=self.nb_epochs, \n",
    "                       batch_size=self.batch_size_train, \n",
    "                       verbose=self.nb_verbose,\n",
    "                        validation_split=0.3,\n",
    "                        shuffle=True)\n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        self.time_train = total_time\n",
    "        if self.nb_verbose == 1 | self.nb_verbose == 2:\n",
    "            print(\"Training time :\", total_time)\n",
    "        \n",
    "        plt.plot(self.history.history['accuracy'])\n",
    "        plt.plot(self.history.history['loss'])\n",
    "        \n",
    "    def _model_prediction(self):\n",
    "        # prediction time\n",
    "        start_time = time.time()\n",
    "        prediction = self.model.predict(self.x_test)\n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        if self.nb_verbose == 1 | self.nb_verbose == 2:\n",
    "            print(\"Prediction time :\", total_time)\n",
    "        self.time_predict = total_time\n",
    "        self.prediction = prediction\n",
    "    \n",
    "    def _model_evaluate(self):\n",
    "        results = self.model.evaluate(self.x_test, \n",
    "                                      self.y_test, \n",
    "                                      batch_size=self.batch_size_test, \n",
    "                                      verbose=self.nb_verbose)\n",
    "        print('test loss, test acc:', results)\n",
    "        self.results = results\n",
    "        self.get_confusion_matrix()\n",
    "\n",
    "    def start(self,dataset, x_train, y_train, \n",
    "                 x_test, y_test, nb_neurons, learning_rate, \n",
    "                 nb_epochs, batch_size_train, recu_dropout,\n",
    "                 activation, \n",
    "                 batch_size_test, nb_verbose):\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        \n",
    "        self.x_train = np.array(x_train)\n",
    "        self.y_train = np.array(y_train)\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.nb_neurons = nb_neurons\n",
    "        self.input_shape = x_train[0].shape\n",
    "        self.nb_labels = 2\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.batch_size_train = batch_size_train\n",
    "        self.recu_dropout = recu_dropout\n",
    "        self.activation = activation\n",
    "        self.batch_size_test = batch_size_test\n",
    "        self.nb_verbose = nb_verbose\n",
    "        \n",
    "        self.model = self._create_model()\n",
    "        self.results = np.array([0,0], dtype=\"float\")\n",
    "        self.predictions = np.array([])\n",
    "        \n",
    "        self.time_train = 0\n",
    "        self.time_predict = 0\n",
    "        \n",
    "        self.algo_start_time = 0\n",
    "        if self.nb_verbose == 1 | self.nb_verbose == 2:\n",
    "            print(\"Model training\")\n",
    "        self._model_fit()\n",
    "        if self.nb_verbose == 1 | self.nb_verbose == 2:\n",
    "            print(\"Model prediction\")\n",
    "        self._model_prediction()\n",
    "        if self.nb_verbose == 1 | self.nb_verbose == 2:\n",
    "            print(\"Model evaluation\")\n",
    "        self._model_evaluate()\n",
    "        if self.nb_verbose == 1 | self.nb_verbose == 2:\n",
    "            print(\"Model backup\")\n",
    "        self._model_save()\n",
    "        if self.nb_verbose == 1 | self.nb_verbose == 2:\n",
    "            print(\"End\")\n",
    "        \n",
    "    def _model_save(self):\n",
    "        # Save only when it's needed\n",
    "        path = 'model'\n",
    "        if os.path.isdir(path) == False:\n",
    "            try:\n",
    "                os.mkdir(path)\n",
    "            except OSError:\n",
    "                print (\"Creation of the directory %s failed\" % path)\n",
    "            else:\n",
    "                print (\"Successfully created the directory %s \" % path)\n",
    "                \n",
    "        nb_saved_model = self._count_files_dir() + 1\n",
    "        #print(nb_saved_model)\n",
    "        name_model = 'model_'+str(nb_saved_model)\n",
    "        \n",
    "        self.model.save(path+'/'+name_model)\n",
    "        log = open(path+'/log.txt','a')\n",
    "        \n",
    "        log.write('\\n'+name_model+'|'+self._to_string())\n",
    "        log.close()\n",
    "        \n",
    "    def _to_string(self):\n",
    "        tmp = str('Dataset:'+self.dataset+\n",
    "                   '|neurons:'+str(self.nb_neurons)+\n",
    "                   '|epochs:'+str(self.nb_epochs) + \n",
    "                   '|batch_size:'+str(self.batch_size_train) + \n",
    "                   '|activation:'+self.activation + \n",
    "                   '|batch_size(test):'+str(self.batch_size_test) + \n",
    "                   '|start_time:'+str(self.algo_start_time) + \n",
    "                   '|time_train:'+ str(self.time_train) + \n",
    "                   '|time_predict:'+str(self.time_predict) + \n",
    "                   '|['+str(self.results[0])+','+str(self.results[1])+']')\n",
    "        return tmp\n",
    "        \n",
    "    def _count_files_dir(self):\n",
    "        count = 0\n",
    "        for path in pathlib.Path(\"model/\").iterdir():\n",
    "            if path.is_file():\n",
    "                count += 1\n",
    "\n",
    "        return count\n",
    "    \n",
    "    def get_confusion_matrix(self):\n",
    "        print(confusion_matrix(y_test.argmax(axis=1), md.prediction.argmax(axis=1)))\n",
    "        \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
